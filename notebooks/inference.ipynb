{"cells":[{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-03-31T02:01:08.780466Z","iopub.status.busy":"2024-03-31T02:01:08.780121Z","iopub.status.idle":"2024-03-31T02:01:08.787194Z","shell.execute_reply":"2024-03-31T02:01:08.786249Z","shell.execute_reply.started":"2024-03-31T02:01:08.780432Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from tqdm.auto import tqdm\n","\n","import torch\n","\n","from peft import PeftConfig, PeftModel\n","from transformers import AutoModelForCausalLM, AutoTokenizer"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-03-31T02:01:08.788788Z","iopub.status.busy":"2024-03-31T02:01:08.788448Z","iopub.status.idle":"2024-03-31T02:01:08.797728Z","shell.execute_reply":"2024-03-31T02:01:08.796612Z","shell.execute_reply.started":"2024-03-31T02:01:08.788740Z"},"trusted":true},"outputs":[],"source":["input_token_len = 1024\n","output_token_len = 100\n","\n","cache_dir = \"/tmp/k7/\""]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-03-31T02:01:08.799597Z","iopub.status.busy":"2024-03-31T02:01:08.799195Z","iopub.status.idle":"2024-03-31T02:01:08.820039Z","shell.execute_reply":"2024-03-31T02:01:08.819149Z","shell.execute_reply.started":"2024-03-31T02:01:08.799541Z"},"trusted":true},"outputs":[],"source":["test_df = pd.read_csv('../data/test.csv')"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-03-31T02:01:08.822927Z","iopub.status.busy":"2024-03-31T02:01:08.822550Z","iopub.status.idle":"2024-03-31T02:01:08.827682Z","shell.execute_reply":"2024-03-31T02:01:08.826658Z","shell.execute_reply.started":"2024-03-31T02:01:08.822897Z"},"trusted":true},"outputs":[],"source":["base_model_name = \"google/gemma-7b-it\"\n","adapter_model_name = \"gemma_public_data_sft_adapter\""]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-03-31T02:01:08.829307Z","iopub.status.busy":"2024-03-31T02:01:08.828971Z","iopub.status.idle":"2024-03-31T02:01:08.842269Z","shell.execute_reply":"2024-03-31T02:01:08.841137Z","shell.execute_reply.started":"2024-03-31T02:01:08.829280Z"},"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-03-31T02:01:08.844226Z","iopub.status.busy":"2024-03-31T02:01:08.843891Z","iopub.status.idle":"2024-03-31T02:01:08.972818Z","shell.execute_reply":"2024-03-31T02:01:08.971840Z","shell.execute_reply.started":"2024-03-31T02:01:08.844202Z"},"trusted":true},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True, cache_dir=cache_dir)\n","if tokenizer.pad_token is None:\n","    tokenizer.pad_token = tokenizer.eos_token"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-03-31T02:01:08.974999Z","iopub.status.busy":"2024-03-31T02:01:08.974564Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.49it/s]\n"]}],"source":["model = AutoModelForCausalLM.from_pretrained(base_model_name,trust_remote_code=True, cache_dir=cache_dir)\n","model = PeftModel.from_pretrained(model, adapter_model_name, cache_dir=cache_dir)"]},{"cell_type":"code","execution_count":24,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["model loaded !!\n"]}],"source":["model.to(device)\n","model.eval()\n","print('model loaded !!')"]},{"cell_type":"code","execution_count":25,"metadata":{"trusted":true},"outputs":[],"source":["def text_generate(ori_text, rew_text, model, tokenizer, input_max_len=512, output_len=20, device='cuda'):\n","    prompt = f\"Instruct: Original Text:{ori_text}\\nRewritten Text:{rew_text}\\nWrite a prompt that was likely given to the LLM to rewrite original text to rewritten text.\\nOutput:\"\n","    inputs = tokenizer(prompt, max_length=input_max_len, truncation=True, return_tensors=\"pt\", return_attention_mask=False)\n","    \n","    input_token_len = len(inputs.input_ids[0])\n","    inputs = {k:v.to(device) for k,v in inputs.items()}\n","    max_len = input_token_len + output_len\n","    \n","    outputs = model.generate(**inputs,\n","                         do_sample=False,\n","                         max_length=max_len,\n","                         pad_token_id=tokenizer.pad_token_id,\n","                         )\n","    text = tokenizer.batch_decode(outputs,skip_special_tokens=True,clean_up_tokenization_spaces=False)[0]\n","    start_index = text.find('Output:')\n","    generated_text = text[start_index+len('Output:'):].strip()\n","    return generated_text"]},{"cell_type":"code","execution_count":26,"metadata":{"trusted":true},"outputs":[],"source":["mean_prompt = \"'Rewrite the following text in the style of [author/style], while preserving the original meaning. Adapt the tone, diction, and stylistic elements to match the specified writing style, aiming to enhance clarity, elegance, and impact.'\""]},{"cell_type":"code","execution_count":27,"metadata":{"trusted":true},"outputs":[],"source":["rewrite_prompts = []"]},{"cell_type":"code","execution_count":34,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:02<00:00,  2.83s/it]"]},{"name":"stdout","output_type":"stream","text":["The competition dataset comprises text passages that have been rewritten by the Gemma LLM according to some rewrite_prompt instruction. The goal of the competition is to determine what prompt was used to rewrite each original text.  Please note that this is a Code Competition. When your submission is scored, this example test data will be replaced with the full test set. Expect roughly 2,000 original texts in the test set.\n","Here is your shanty: (Verse 1) The text is rewritten, the LLM has spun, With prompts so clever, they've been outrun. The goal is to find, the prompt so bright, To crack the code, and shine the light. (Chorus) Oh, this is a code competition, my dear, With text and prompts, we'll compete. Two thousand texts, a challenge grand, To guess the prompts, hand over hand.(Verse 2) The original text, a treasure lost, The rewrite prompt, a secret to be\n","The prompt that was given to the LLM to rewrite the original text into the rewritten text.\n","\n","**Note:** This is a fictional prompt and does not represent the actual prompt used in the competition.\n","\n","**Example:**\n","\n","Original Text: The cat sat on the mat.\n","\n","Rewritten Text: The cat sat on the mat, purring.\n","\n","Prompt: Make the text more descriptive and vivid. Add a sense of emotion.\n","```\n","Prompt: Make the text more descriptive and vivid.\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["for i, row in tqdm(test_df.iterrows(), total=len(test_df)):\n","    prompt = mean_prompt        \n","    try:\n","        prompt = text_generate(row['original_text'],\n","                               row['rewritten_text'],\n","                               model,\n","                               tokenizer,\n","                               input_token_len,\n","                               output_token_len,\n","                               device,\n","                              )\n","        print(row['original_text'])\n","        print(row['rewritten_text'])\n","        print(prompt)\n","    except:\n","        pass\n","        \n","    rewrite_prompts.append(prompt)"]},{"cell_type":"code","execution_count":29,"metadata":{"trusted":true},"outputs":[],"source":["test_df['rewrite_prompt'] = rewrite_prompts"]},{"cell_type":"code","execution_count":30,"metadata":{"trusted":true},"outputs":[],"source":["sub_df = test_df[['id', 'rewrite_prompt']]\n","sub_df.to_csv('submission.csv', index=False)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":7806901,"sourceId":67121,"sourceType":"competition"},{"datasetId":3600418,"sourceId":6572938,"sourceType":"datasetVersion"},{"datasetId":4701009,"sourceId":7986199,"sourceType":"datasetVersion"},{"sourceId":164964691,"sourceType":"kernelVersion"},{"modelInstanceId":8658,"sourceId":10716,"sourceType":"modelInstanceVersion"},{"modelInstanceId":17852,"sourceId":21555,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":4}
